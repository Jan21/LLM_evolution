{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c919846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Connect to database and load all data\n",
    "conn = sqlite3.connect('experiments.db')\n",
    "\n",
    "# Load the full database\n",
    "df = pd.read_sql_query(\"SELECT * FROM experiments\", conn)\n",
    "conn.close()\n",
    "\n",
    "print(f\"Total experiments: {len(df)}\")\n",
    "print(f\"Database shape: {df.shape}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Display basic info\n",
    "print(\"COLUMN INFO:\")\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Show first few rows (excluding the long text columns for readability)\n",
    "display_cols = ['id', 'timestamp', 'd_model', 'num_heads', 'num_layers', 'd_ff', \n",
    "                'learning_rate', 'batch_size', 'val_loss', 'val_accuracy', \n",
    "                'val_path_validity', 'val_edge_accuracy', 'iteration']\n",
    "\n",
    "print(\"FIRST 10 EXPERIMENTS:\")\n",
    "print(df[display_cols].head(10))\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"SUMMARY STATISTICS:\")\n",
    "numeric_cols = ['d_model', 'num_heads', 'num_layers', 'd_ff', 'learning_rate', \n",
    "                'val_loss', 'val_accuracy', 'val_path_validity', 'val_edge_accuracy', 'iteration']\n",
    "print(df[numeric_cols].describe())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Best and worst performers\n",
    "print(\"TOP 5 BEST MODELS (lowest val_loss):\")\n",
    "best_models = df.nsmallest(5, 'val_loss')[display_cols]\n",
    "print(best_models)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"TOP 5 WORST MODELS (highest val_loss):\")\n",
    "worst_models = df.nlargest(5, 'val_loss')[display_cols]\n",
    "print(worst_models)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Iteration analysis\n",
    "print(\"EXPERIMENTS PER ITERATION:\")\n",
    "iteration_counts = df.groupby('iteration').size()\n",
    "print(iteration_counts)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"BEST MODEL PER ITERATION:\")\n",
    "best_per_iteration = df.loc[df.groupby('iteration')['val_loss'].idxmin()]\n",
    "print(best_per_iteration[['iteration', 'id', 'val_loss', 'd_model', 'num_heads', 'num_layers']])\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Distribution of validation loss\n",
    "axes[0,0].hist(df['val_loss'], bins=20, alpha=0.7, edgecolor='black')\n",
    "axes[0,0].set_title('Distribution of Validation Loss')\n",
    "axes[0,0].set_xlabel('Validation Loss')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# 2. Val loss over time (by experiment ID)\n",
    "axes[0,1].plot(df['id'], df['val_loss'], 'o-', alpha=0.6)\n",
    "axes[0,1].set_title('Validation Loss Over Experiments')\n",
    "axes[0,1].set_xlabel('Experiment ID')\n",
    "axes[0,1].set_ylabel('Validation Loss')\n",
    "\n",
    "# 3. Val loss by iteration\n",
    "if 'iteration' in df.columns:\n",
    "    df.boxplot(column='val_loss', by='iteration', ax=axes[1,0])\n",
    "    axes[1,0].set_title('Validation Loss by Iteration')\n",
    "    axes[1,0].set_xlabel('Iteration')\n",
    "\n",
    "# 4. Correlation heatmap of key metrics\n",
    "metrics = ['val_loss', 'val_accuracy', 'val_path_validity', 'val_edge_accuracy', 'd_model', 'num_heads', 'num_layers']\n",
    "correlation_data = df[metrics].corr()\n",
    "sns.heatmap(correlation_data, annot=True, cmap='coolwarm', center=0, ax=axes[1,1])\n",
    "axes[1,1].set_title('Correlation Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show evolution progress if multiple iterations exist\n",
    "if df['iteration'].nunique() > 1:\n",
    "    print(\"EVOLUTION PROGRESS:\")\n",
    "    evolution_progress = df.groupby('iteration').agg({\n",
    "        'val_loss': ['min', 'mean', 'std'],\n",
    "        'val_accuracy': ['max', 'mean'],\n",
    "        'val_path_validity': ['max', 'mean']\n",
    "    }).round(4)\n",
    "    print(evolution_progress)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Plot evolution progress\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    iteration_stats = df.groupby('iteration')['val_loss'].agg(['min', 'mean'])\n",
    "    plt.plot(iteration_stats.index, iteration_stats['min'], 'o-', label='Best', color='green')\n",
    "    plt.plot(iteration_stats.index, iteration_stats['mean'], 'o-', label='Mean', color='blue')\n",
    "    plt.title('Val Loss Evolution')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 2) \n",
    "    iteration_stats = df.groupby('iteration')['val_accuracy'].agg(['max', 'mean'])\n",
    "    plt.plot(iteration_stats.index, iteration_stats['max'], 'o-', label='Best', color='green')\n",
    "    plt.plot(iteration_stats.index, iteration_stats['mean'], 'o-', label='Mean', color='blue')\n",
    "    plt.title('Val Accuracy Evolution')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    iteration_stats = df.groupby('iteration')['val_path_validity'].agg(['max', 'mean'])\n",
    "    plt.plot(iteration_stats.index, iteration_stats['max'], 'o-', label='Best', color='green')\n",
    "    plt.plot(iteration_stats.index, iteration_stats['mean'], 'o-', label='Mean', color='blue')\n",
    "    plt.title('Path Validity Evolution')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Path Validity')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Hyperparameter analysis\n",
    "print(\"HYPERPARAMETER ANALYSIS:\")\n",
    "print(\"\\nBest d_model values:\")\n",
    "print(df.nsmallest(10, 'val_loss')['d_model'].value_counts())\n",
    "\n",
    "print(\"\\nBest num_heads values:\")\n",
    "print(df.nsmallest(10, 'val_loss')['num_heads'].value_counts())\n",
    "\n",
    "print(\"\\nBest learning_rate values:\")\n",
    "print(df.nsmallest(10, 'val_loss')['learning_rate'].value_counts())\n",
    "\n",
    "# Display the complete dataframe at the end for detailed inspection\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COMPLETE DATABASE (use df variable for further analysis):\")\n",
    "print(f\"Access with: df.head(), df.tail(), df[df['val_loss'] < 1.0], etc.\")\n",
    "print(f\"Available columns: {list(df.columns)}\")\n",
    "\n",
    "# Make df available for interactive use\n",
    "globals()['df'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d7bb60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
